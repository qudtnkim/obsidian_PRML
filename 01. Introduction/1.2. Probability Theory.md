 1.2. Probability Theory

- 패턴 인식 분야에 있어 #불확실성 #uncertainty 는 가장 중요한 개념 중에 하나임.
- 불확실성이 발생하는 이유는 
> 충분하지 못한 데이터
> 관찰된 데이터에 포함된 노이즈

## 확률의 법칙
- sum rule
$$p(X) = \sum_Y p(X,Y) \qquad{(1.10)}$$
- product rule

$$p(X,Y)=p(Y|X)p(X) \qquad{(1.11)}$$
- 다음으로 이를 이용하여 베이즈 정리를 기술한다.

$$p(Y|X)=\dfrac{p(X|Y)p(Y)}{p(X)} \qquad{(1.12)}$$
$$p(X)=\sum_Y{p(X|Y)p(Y)} \qquad{(1.13)}$$
## 1.2.1. 확률 밀도 (Probabilty densities)

이산(discrete)적인 사건에 대한 확률식을 다뤄왔었다면, 연속적인 입력 값에 대한 확률식을 고려해보아야 하낟.

실수범위의 입력값에 대해서는 확률값을 모두 나열하기 어렵다.

   - 예를 들어 몸무게 60kg와 60.0001kg 사이에도 많은 실수 값이 존재한다.
   - 이런 경우 각각의 실수 값에 개별적인 확률값을 부여하기는 불가능하다.

- 따라서 확률 값을 구간(range)으로 표현한다. : $R(x, x+\delta{x})$
- 여기서 $\delta{x}$ 가 0에 수렴한다면, 값은 $p(x)$ 가 된다.

$$p(x \in (a, b)) = \int_{a}^{b}p(x)dx \qquad{(1.24)}$$
- 여기서 $P(x)$는 확률의 누적식(즉, *CDF*)이 되고 $p(x)$ 는 확률 밀도(probability density)가 된다.
![[Pasted image 20220902154634.png]]
#확률누적식 #CDF 
- 확률 밀도는 다음과 같은 성질이 있다.
$$p(x)\ge 0 \qquad{(1.25)}$$
$$\int{p(x)dx}=1 \qquad{(1.26)}$$

- 이 교재는 *PDF* 에 대한 설명이 자세히 나오지는 않는다. 대략적인 것은 이해하고 있으리라 생각한다.

- 입력되는 변수가 비선형인 값으로 변경되는 경우가 있을 수 있다. (예를 들면 $y \rightarrow x^2$ 과 같은 식)
- 
- 이 경우 확률식도 함께 변환되어야 되는데 다음과 같은 성질을 만족한다.
$$x=g(y)$$
$$f(x) \rightarrow \tilde{f}(y)=f(g(y))$$
- 결국 다음과 같이 사용 가능하다.
$$p_y(y)=p_x(x)\left|\dfrac{dx}{dy}\right|=p_x(g(y))\left|g'(y)\right| \qquad{(1.27)}$$
- x 에 대해 확률 함수 p(x) 가 주어졌을 때 구간 $-\infty, z$ 에 대한 확률 값을 누적 분포 함수 (*cumulative distribution function*)라고 한다.

$$P(z) = \int_{-\infty}^{z} p(x)dx\qquad{(1.28)}$$

- 그림 1.12 를 보면 이해하기 쉽다. P(x) 를 미분하면 p(x)를 얻을 수 있다.

-----

- 확률 함수는 벡터(vector) 변수에서도 동일하게 적용할 수 있다.
- 예를 들어 어떤 연속 변수 $(x$) 가 $( ${ x_1, ..., x_D $} $) 로 구성된다면,
- 확률 함수는 $( p({\bf x}) = p(x_1,...,x_D) $) 로 고려될 수 있다.
- 마찬가지로 다음의 제약 조건이 성립한다.

$$p({\bf x}) \ge 0 \qquad{(1.29)}$$

$$\int p({\bf x}) d{\bf x} = 1 \qquad{(1.30)}$$

-----

- 연속 확률 밀도(*PDF*)에서도 *sum rule*, *product rule* 은 모두 적용 가능하다. (증명은 생략.)
    - 착각해서는 안되는 부분은 실제 확률 값과 밀도 함수의 반환 값은 서로 다른 성질이다.
    - 연속적인 확률 밀도에서 $( p(x) $) 를 통해 얻어진 실수 값은 실제 확률 값이 아니라 확률 함수의 반환 값이다.
    - 따라서 아래 식은 연속 확률 함수에 대한 *sum*, *product rule* 을 의미한다.
    - 이후에도 혼동이 되지 않으려면 *PMF* 와 *PDF* 의 차이를 명확하게 이해하여야 한다.
        - 간단히 정리하자면 *PMF* 의 값은 그 자체로 확률 값이지만 *PDF* 의 경우 그 자체로 확률 값이 아니라 구간 적분해야 확률값이 된다.
        
$$p(x)=\int{p(x,y)dy} \qquad{(1.31)}$$
        
$$p(x,y)=p(y|x)p(x) \qquad{(1.32)}$$


## 1.2.2. 평균과 공분산 (Expactations and covariances)
- 확률식에서 주어진 데이터에 대한 무게 중심을 구하는 것은 매우 중요한데, 주로 평균을 사용한다. 
- 여기서는 함수 결과에 대한 평균 값을 설명한다 
- 이산확률함수와 연속확률함수에 대한 설명이다.
$$E[f]=\sum_x{p(x)f(x)} \qquad{(1.33)}$$
$$E[f]=\int{ {p(x)f(x)} dx} \qquad{(1.34)}$$
- 연속 함수에 댛나 평균값을 근사하는 방법이 있는데, 최대한 많은 샘플을 생성해서 샘플을 통해 평균을 구하는 방법이 있다. 
$$E[f]\simeq\dfrac{1}{N}\sum_{n=1}^{N}{f(x_n)} \qquad{(1.35)}$$
- N -> $\infty$ 하면 근사 값이 실제 값과 거의 같아지게 된다. 위의 식이 언급되는 이유는 연속 확률 함수에 대한 샘플링 기법을 소개하기 위함임. 
- 여거 개의 변수를 사용하는 함수에 대해 평균 값을 표기할 경우가 있다.
- 이 때에는 평균에 사용하는 주변수를 함께 기술한다.
$$E_x[f(x,y)] \qquad{(1.36)}$$
- 위의 경우에는 E_x[f(x,y)]자체가  y $) 에 대한 함수처럼 사용될 수 있다.

- 조건부 평균(기대값)도 마찬가지로 정의할 수 있다.
$$E_x[f|y]=\sum_x{p(x|y)f(x)} \qquad{(1.37)}$$
- 이에 대한 분산은 다음과 같다.
$$var[f]=E[(f(x)-E[f(x)])^2] \qquad{(1.38)}$$
## 함수의 평균오차의 제곱의 평균

위의 식을 아래와 같이 전개 할 수도 있다 제곱의 평균 - 평균의 제곱 
$$var[f]=E[f(x)^2]-E[f(x)]^2 \qquad{(1.39)}$$

- 지금까지 함수 f 에 대해서 전개했지만 이를 변수 x 로 놓고 처리해도 식이 성립한다. f(x)=x 
$$var[x]=E[x^2]-E[x]^2 \qquad{(1.40)}$$
- 2개의 랜덤변수 x,y 에 대한 공분산 은 다음과 같이 정의 한다.
- 위의 1.40 식과 유사한 형임을 알 수 있다.
$$cov[x,y]=E_{x,y}[(x-E[x])(y-E[y])] = E_{x,y}[xy]-E[x]E[y] \qquad{(1.41)}$$

- 위의 식에서  x 와 y는 벡터로 확장 가능하다. (이 책은 벡터를 볼드체로 표현한다.)
$$cov[{\bf x},{\bf y}]=E_{\bf x,y}[({\bf x}-E[{\bf x}])({\bf y}^T-E[{\bf y}^T])] = E_{\bf x,y}[{\bf xy}^T]-E[{\bf x}]E[{\bf y}^T] \qquad{(1.42)}$$


## 1.2.3. 베이지언 확률 (Bayesian probabilities)
- 지금까지 확률을 고려하는데 있어 임의적으로 발생하는 사건에 대한 빈도를 바탕으로 식을 전개해 왔다.
- 이런 방식을 #빈도론자 ( #Frequentist ) 방식이라고 한다.
- 이제 이와는 대조적인, #베이지언 ( #Bayesian ) 방식에 대해 알아보도록 하자

- 베이지안 관점에서는 모든 것이 불확실하며 (이를 정량화해서 표현한다.) 믿음의 정도로 해석하는 관점이 베이지안의 관점이다. 
> 발생하지 않은 사건에 대해서도 모델링이 가능함을 의미한다.
> 사전 확률 모델을 작성하고, 일부의 측량 정보를 더해 사후확률을 보정하는 방식을 취한다.

커브 피팅 문제에서는 모수 w 가 알려지지 않은 고정된 값으로 여겨지지만, 베이지
안 방식은 모든 값이 확률이므로 이를 하나의 확률변수로 고려한다.
$$p({\bf w}|D)=\dfrac{p(D|{\bf w})p({\bf w})}{p(D)} \qquad{(1.43)}$$

위의 식은 이미 사전확률 p(w)를 통해서 w의 불확실한 정도를 수식에 반영하고 있다. 

==$D$를 관측한 후의 w에 대한 불확실성을 사후 확률 p(w|D) 로 표현한 것이다. p(D|w) 는 관측 데이터 집합 D를 바탕으로 계산할 수 있다. ==


이는 모수(parameter)에 대한 사전(prior) 확률 분포를 의미한다.

- 실제 데이터를 통해 예측된 w 의 확률을 조합하여 w의 사후 확률을 기술한다.
$$posterior \propto likelihood \times prior \qquad{(1.44)}$$
- 분모로 포함되는 p(D)의 경우 확률식에 대한 정규화 요소로 다음과 같이 정의된다.
$$p(D)=\int{p(D|{\bf w})p({\bf w})d{\bf w}} \qquad{(1.45)}$$
- 위의 식 또한 무시하면 안되는데, 모델 선택(*model selection*)과 관련 깊은 수식이다.

## ==빈도론자(Frequentist)와 베이지언(Bayesian)의 가능도 함수에 대한 입장 차==

MLE in frequentist
- w는 알려지지 않은 고정된 파라미터 값이다. 
- ML 를 추정하는 것으로 p(D|$w_{ML}$) 를 최대로 만드는 $w_{ML}$ 를 구한다.
- 빈도론에서 w는 고정된 파라미터 값이지만 알려져 있지 않으므로 데이터로부터 추정해야한다.

- 기계학습 분야에서는 주로 log-likehood 를 사용하며, 단조 증가함수이다.

MLE in bayesian
- 파라미터 w 를 랜덤변수로 간주하고 확률 분포로 사용한다. 
- D는 고정한 상태로 진행한다. 확률 함수 등으로 얻어지는 w는 얻어진 확률 함수의 평균이나 최빈값을 고정값 대신 사용할 수도 있다. ( #MAP ) [[최대사후분포]]
- MLE 에서는 동전을 3번 던져 앞면이 모두 나온 경우 파라미터 $\theta$ 의 값이 그냥 1이 된다.
- 하지만 베이지안 방식에서는 사전확률로 인해 이 값을 보정해줄 수 있음.

## 1.2.4. 가우시안 분포 (Gaussian distribution)
#가우시안분포

가우시안 확률 분포는 다음과 같은 식으로 표현한다.

$$N(x\;|\;\mu, \sigma^2)=\dfrac{1}{(2\pi\sigma^2)^{1/2}}\exp\left\{-\dfrac{1}{2\sigma^2}(x-\mu)^2\right\} \qquad{(1.46)}$$

- 이 확률 분포는 2개의 파라미터(모수, parameter)가 존재한다. 
   - $\mu$ : 평균(mean)
   - $\sigma$ : 표준편차(standard deviation)

   - 표준 편차의 제곱(=분산)의 역수는 정확도 라고 한다.$\beta = \frac {1}{\sigma^{2}}$ 
   - 수식 전개상 분산보다는 정확도를 사용해 계산하는 것이 편리한 경우가 많음
   #정확도 #beta 
   - 분산과 같은 개념으로 취급해도 무방
   
- 가우시안 분포를 정규 분포라고 부른다. 이 분포는 다음과 같은 성질이 있다.
$$N(x\;|\;\mu, \sigma^2)\gt0 \qquad{(1.47)}$$
$$\int_{-\infty}^{\infty}N(x\;|\;\mu, \sigma^2)\;dx=1 \qquad{(1.48)}$$
$$E[x]=\int_{-\infty}^{\infty}N(x\;|\;\mu, \sigma^2){\cdot}x\;dx=\mu \qquad{(1.49)}$$
$$E[x^2]=\int_{-\infty}^{\infty}N(x\;|\;\mu, \sigma^2){\cdot}x^2\;dx=\mu^2+\sigma^2 \qquad{(1.50)}$$
$$var[x]=E[x^2]-E[x]^2=\sigma^2 \qquad{(1.51)}$$

위의 설명한 내용은 x가 1차원(단변량)인 경우에 대한 것이며, 이는 D 차원으로 확장 가능하다.(가우시안 분포의 장점이라고 할 수 있다.)

- 이를 D 차원으로 확장하면 다변량(multinomial) 가우시안 분포라고 부른다. 식은 다음과 같다.
$$N({\bf x}|{\pmb \mu}, {\pmb \Sigma})=\dfrac{1}{(2\pi)^{D/2}|{\pmb \Sigma}|^{1/2}}\exp\left\{-\dfrac{1}{2}({\bf x}-{\pmb \mu})^T{\pmb \Sigma}^{-1}({\bf x}-{\pmb \mu})\right\} \qquad{(1.52)}$$
- 하나의 관찰 데이터 집합 ${\bf x}=(x_1,...,x_N)^T$ 이 주어졌다고 해보자.
- 이 데이터 집합 하나가 관찰될 수 있는 확률은?

- 각각의 데이터가 발현되는 가능성은 서로 독립적이므로( 즉, *i.i.d* ) 이 확률값들은 모두 독립 사건으로 처리할 수 있다. 
   - 즉, 각 사건이 독립적이기 때문에 확률의 곱으로써 표현이 된다.

- 하나의 데이터는 동일한 분포로부터 발현되었을 것이므로 이 확률을 다음과 같이 표기할 수 있다.

$$p({\bf x}|\mu, \sigma^2)=\prod_{n=1}^{N}{N(x_n\;|\;\mu, \sigma^2)} \qquad{(1.53)}$$

- 이것을 그림으로 나타내면 다음과 같다.
![[Pasted image 20220902165211.png|500]]

- 어떤 관찰 데이터가 하나의 가우시안 분포를 따른 다고 생각하면, 얻는 것은 관찰 데이터 집합이고, 이를 이용해서 원래의 가우시안 분포를 결정하는 것이 목적임.

- 특정 가우시안의 평균과 분산 값을 정하는 것과 같은 뜻.
-  $p(x|\mu,\sigma^2)$ 의 분포가 이러한 결과를 만들어 낼 만 하다고 보이는 평균과 분산을 찾는 것이 목적이며, 이를 파라미터 추정이라고 한다.
$$\ln{p({\bf x}\;|\;\mu, \sigma^2)} = -\dfrac{1}{2\sigma^2}\sum_{n=1}^{N}{(x_n-\mu)^2}-\dfrac{N}{2}\ln\sigma^2-\dfrac{N}{2}\ln(2\pi) \qquad{(1.54)}$$
- 위의 함수 값을 최대로 만드는 파라미터 값은 편미분을 이용해 구한다. (모수가 2개이므로 편미분을 이용하면 된다.)
$$\mu_{ML}=\dfrac{1}{N}\sum_{n=1}^{N}x_n \qquad{(1.55)}$$
$$\sigma_{ML}^2=\dfrac{1}{N}\sum_{n=1}^{N}(x_n-\mu_{ML})^2 \qquad{(1.56)}$$

- 가능도 함수를 가장 크게 만드는 모수 값을 추정하므로 이를 *MLE* (*Maximum likelihood estimation*)라고 한다.

- *MLE* 를 통해 얻어진 결과는 각각 샘플에 대한 평균과 분산 값이다.

- 이후에 *MLE* 접근 방식의 한계점에 대해서 다루어질 예정이다.
- 사실 위의 결과에서 분산 값은 *bias* 되어 있다.
    - *MLE* 에서 보여지는 오버피팅의 한 예이다.
- 이 값들의 평균 값은 다음과 같다. (결국 실제 평균이 된다.)

$$E[\mu_{ML}]=\mu \qquad{(1.57)}$$

- 분산 값의 평균은 다음과 같다.

$$E[\sigma_{ML}^2]=\left(\dfrac{N-1}{N}\right)\sigma^2 \qquad{(1.58)}$$

- 위의 식으로부터 얻어진 아래의 분산 값은 unbias되어 있음을 알 수 있다.

$$\tilde{\sigma}^2=\dfrac{N}{N-1}\sigma_{ML}^2=\dfrac{1}{N-1}\sum_{n=1}^{N}(x_n-\mu_{ML})^2 \qquad{(1.59)}$$
==가우시안 분포의 분포의 최댓값 최빈값( #mode ) 는 평균값 $\mu$ 와 동일하다.==


 
## 1.2.5. 다시보는 커브 피팅 (Curve fitting re-visited)
- 앞서 우리는 다항식을 이용하여 커브 피팅 방법을 처리하는 방법을 살펴보았다. (Error 함수를 이용)
- 이제 이 문제를 확률적인 관점에서 해석해보도록 하자.
   - 이를 통해 에러 함수(error function)와 정칙화(regularization)에 대한 통찰을 얻을 수 있을 것이다.
   - 또한 이를 확장하여 베이지안 관점에서의 해석법을 다루게 될 것이다.

- 커브 피팅 문제의 최종 목표는 임의로 제공된  x 에 대해 이 때의  t 값을 예측하여 제공하는 것이다.
- 입력 데이터 $x=(x_1,...,x_N)^{T}$ 에 대응되는 타겟 값은 $t=(t_1,...,t_N)^{T}$ 이다.
- 우리는 주어진 환경을 다음과 같이 모델링할 수 있다. (그림을 참고하여 확인하자)
   - 앞절에서 다루던 모델과는 약간 다르게 보일 것인데, 노이즈를 가우시안 분포로 고려하고 있다.
   - 식의 차이를 잘 살펴보도록 하자. ( 식에 사용된 $\beta$ 를 눈여겨 봐야 한다.)

$$p(t\;|\;x, {\bf w}, \beta)=N(t\;|\;y(x,{\bf w}), \beta^{-1}) \qquad{(1.60)}$$

- 여기서 $\beta$ 는 노이즈의 정확도(precision)로써 실제 분포의 분산 값의 역수이다.

- 사실 이해를 하자면 간단한데, 한 점이 주어질 때 이를 나타낼 수 있는 근사식과 정규분포 형태의 노이즈 함수를 조합한 형태의 모델이다.

- 따라서 근사식을 현재 축의 중심에 두고 정규 분포의 형태를 가지는 노이즈 함수를 도입한다.
   - 보통 가우시안 분포의 평균(mean) 파라미터에 상수(const)만을 사용하는 것이 일반적인 형태이나 이렇게 함수가 올 수도 있다.
   - 평균이 들어올 자리에 $y$ 함수가 들어앉아 있다.
   
- 자, 이제 실제 샘플 데이터를 이용하여 해당 데이터가 존재할 확률을 정의해보자.
- Generative 모델이므로 분포를 통한 파라미터 추론이 그 시작이 될 것이다.
- 가능도 함수를 정의하여 보자.
    - 즉, 실제 얻어진 샘플의 결과와 이에 영향을 미치는 모수들의 관계를 확률식으로 표현한다.

$$p({\bf t}|{\bf x}, {\bf w}, \beta) = \prod_{n=1}^{N}N(t_n|y(x_n, {\bf w}), \beta^{-1}) \qquad{(1.61)}$$

- 로그를 취하고 이 가능도 함수 값을 최대로 만드는 파라미터 값을 추정한다.

$$\ln p({\bf t}|{\bf x}, {\bf w}, \beta) = -\dfrac{\beta}{2}\{y(x_n, {\bf w})-t_n\}^2+\dfrac{N}{2}\ln\beta-\dfrac{N}{2}\ln(2\pi) \qquad{(1.62)}$$

- 이것으로부터 *MLE* 를 이용해 얻어지는 w 를 $w_{ML}$ 로 표기한다.
- 여기서 마지막 2개의 텀(term)은 사실 $w$ 를 구하는 것과 아무런 관련이 없다. 
- 따라서 첫번째 항의 $\beta$ 를 잠시 1로 두고 보면 $\beta=1$ 기존의 에러 함수와 차이가 없다는 것을 이해할 것이다.
    - 결국 sum-of-squares error function 이다.
- 다시 *MLE* 를 이용하여 $\beta$ 값도 손쉽게 얻을 수 있다. (즉, 이번에는 식을 $\beta$ 로만 미분한다.)
$$\dfrac{1}{\beta}=\dfrac{1}{N}\sum_{n=1}^{N}\{y(x_n, {\bf w}_{ML})-t_n\}^2 \qquad{(1.63)}$$
- 이렇게 얻어진 $w$ 와 $\beta$ 값을 이용하여 새로운 데이터 $x_{new}$ 의 타겟 값을 예측해 볼 수도 있다.
- 이런 확률 모델을 predictive 분포라고 부른다.

$$p(t_{new}\;|\;x_{new}, {\bf w}_{ML}, \beta_{ML})=N(t_{new}\;|\;y(x_{new}, {\bf w}_{ML}), \beta_{ML}^{-1}) \qquad{(1.64)}$$

- 사실 여기서 베이지언 관점으로 식을 확장하여 파라미터 자체에 대한 확률 분포를 추가로 고려해볼 수도 있다.
    - 즉, 사용되는 파라미터가 하나의 고정된 값이 아니라 랜덤 변수라고 가정한다.
    - 뒤에서 자세히 다루겠지만 일단 $w$ 에 대한 사전(prior) 분포를 기술해보자.
    
$$p({\bf w}|\alpha)=N({\bf w}|0, \alpha^{-1}{\bf I})=\left(\dfrac{\alpha}{2\pi}\right)^{(M+1)/2}\exp\left\{-\dfrac{\alpha}{2}{\bf w}^T{\bf w}\right\} \qquad{(1.65)}$$

- 여기서 $( \alpha $) 는 분포의 정확도(precision)가 된다. 
- $( {\bf w} $) 는 그냥 가우시안 분포를 따른다고 가정한다는 것을 알 수 있다. (이 때의 사전 분포의 평균 값은 0으로 가정.)
- $( M+1 $) 은 벡터 $( {\bf w} $) 의 개수로 다항식 예제에서는 최대 $( M^{th} $) 의 차수를 가지는 다항식이 만들어진다.
- $( \alpha $) 와 같은 변수를 초모수(hyper-parameter) 즉, **하이퍼 파라미터** 라고도 부른다.
- 베이즈 룰을 이용하여 식을 다음과 같이 분해 가능하다.

$$p({\bf w}|{\bf x}, {\bf t}, \alpha, \beta) \propto p({\bf t}|{\bf x}, {\bf w}, \beta)p({\bf w}|\alpha) \qquad{(1.66)}$$

- 이 식에 가우시안 분포를 이용해서 전개를 하면 다음을 얻을 수 있다.

$$\dfrac{\beta}{2}\sum_{n=1}^{N}\{y(x_n, {\bf w}-t_n)\}^2+\dfrac{\alpha}{2}{\bf w}^T{\bf w} \qquad{(1.67)}$$

- 결국 앞서 다루었던 정칙화 에러 함수(regularized sum-of-squares error function) 와 식이 동일하다. (1.1절) 
    - 위의 식에서 $( \lambda $) 만 $( \lambda=\alpha/\beta $) 로 치환하면 된다.
    - 이번 절에서는 베이지언 방식의 세부적인 전개 방식은 다루고 있지 않다.
        - 어렵다고 느껴지면 3장에서 보도록 하자.
        - 베이지언 방식을 사용하면 앞서 사용한 정칙화(regulrazation) 효과를 동일하게 가지게 되는 식이 유도된다는 것만 확인하고 가자.

## 1.2.6. 베이지언 커브 피팅 (bayesian curve fitting)
- 앞서서 잠깐 $( p({\bf w} \| \alpha) $) 에 대한 논의를 했었다. 이게 사실 베이지언 방식이다.
- 완전한 베이지안(fully Bayesian) 접근법에서는 실제 가능한 모든 $( {\bf w} $) 에 대한 값을 반영해야 한다. 
    - 즉, $( {\bf w} $) 를 고정된 값이 아닌 랜덤변수로 고려한다.
    - 이후에도 언급되겠지만 변수를 알려지지 않은 고정된 값으로 취급하는가, 랜덤 변수로 취급하는가에 따라 식이 달라지는 경우가 많다.
        - 고정된 값인 경우 이를 임의의 값으로 결정하기만 하면 그냥 평범한 상수(const) 값이 되어버리지만,
        - 랜덤 변수로 취급하는 경우에는 특정한 값으로 취급하기보단 하나의 확률 값으로 취급하기 때문에
        - 보통은 확률 함수로써 변수를 표현하게 된다.
        
- 따라서 주변(marginalization) 확률 분포를 통한 베이지안 방식을 도입하여 이를 해결한다.
- 모수(parameter)에서는 모든 가능한 범위를 확률함수로 표현한다. 
    - 즉, 하나의 모수가 어떤 분포를 따른다고 가정하고 (랜덤변수이므로) 이에 대한 모수, 즉 모수의 모수를 고려해야 한다.
    - 모수의 모수를 초모수(hyper-parameter)라고 한다.
    - 여기서 잠깐? 모수에 대한 모수, 즉 초모수가 존재한다니?
    - 그러면 초모수(hyper-parameter)의 모수(parameter)는 초초모수(hyper-hyper-parameter)인가? 
        - 농담같지만 실제 존재하는 개념이다.
        - recursive 라는 말이 괜히 있는게 아니다.
    - 하지만 여기서는 논의를 간단하게 하기 위해 초모수 $( \alpha $) 와 $( \beta $) 값을 알려지지 않은 고정된 값으로 취급하여 모델을 전개한다.
        - 즉, 모델에 직접적으로 영향을 주고 있는 모수는 랜덤 변수로 고려하여 어떤 분포로 표현하지만,
        - 이렇게 고려된 모수의 분포에 대한 모수(즉, 초모수)는 고정된 (하지만 알지 못하는) 값으로 취급한다는 것이다.
        - 초모수는 *MLE* 에서의 모수의 역할이라고 생각하면 쉽다.
            - 따라서 우리가 *MLE* 로 모수를 추정할 때 사용했던 그런 방식으로 초모수 값을 추정할 것이다.
        
- 기존 커브 피팅 문제에서는 $( {\bf x} $) 와 이 때의 타겟 $( {\bf t} $) 벡터를 이용하여 모델을 구성하고 새로운 데이터 $( x $) 에 대해 $( t $) 를 예측하는 방식을 취했다.
- 그러나 베이지언 방식에서는 기존의 데이터를 통해 새로운 데이터를 예측하는 모델을 하나의 수식으로 정리 가능하다.

$$p(t|x, {\bf x}, {\bf t})=\int{p(t|x, {\bf w})p({\bf w}|{\bf x}, {\bf t})}d{\bf w} \qquad{(1.68)}$$

- 이를 예측 분포(predictive distribution)라고 부른다.
    - 기존의 샘플 데이터는 벡터 $( ({\bf x}, {\bf t}) $) 로 표기하고 예측할 데이터는 $( (x, t) $) 가 된다.
    - 베이지언 방식에서는 자주 등장하는 형태이므로 유심히 살펴보기 바란다.
    - 이 방식이 좋은 점은 특정한 $( {\bf w} $) 값을 고정하는 것이 아니라 $( {\bf w} $) 에 대한 모든 가능성이 확률 함수를 통해 모델에 이미 다 반영이 되어 있다는 것.
    - *MLE* 에서도 없는 개념은 아니지만 베이지언 방식에서는 대놓고 이런 방식을 선호한다. (업데이트 모델)
        - 3장에서 사후 분포 결과를 다시 사전 분포로 놓고 반복하는 예측 모델을 보게 될 것이다.

- 여기서 적분식 내에서 두번 째 텀을 파라미터에 대한 사후분포(posterior)라고 하고 이를 구하는 방식으로 전개된다.
- 유사하게, 이런 예측 분포도 하나의 가우시안 분포로 고려할 수 있는데 이렇게 해서 얻어지는 분포를 다음과 같이 표기할 수 있다.

$$p(t\;|\;x, {\bf x}, {\bf t})=N(t\;|\;m(x), s^2(x)) \qquad{(1.69)}$$

$$m(x)=\beta\phi(x)^T{\bf S}\sum_{n=1}^{N}\phi(x_n)t_n \qquad{(1.70)}$$
$${\bf S}^{-1}=\alpha{\bf I}+\beta\sum_{n=1}^{N}\phi(x_n)\phi(x_n)^T \qquad{(1.71)}$$

- 일단은 식을 한번 살펴보는 정도로 마무리하면 된다. 3장에서 이에 대한 자세한(지겹도록!) 설명을 하게 될 것이다.
- 이런 식을 통해 sinusoidal 예제를 어떻게 해결하는지 간단하게 그림으로 확인해보자.

![figure1.17]({{ site.baseurl }}/images/Figure1.17.png){:class="center-block" height="230px"}

- 이 그림은 기저함수를 다항식(polynomial)으로 선택하여 만든 모델로, $( M=9 $) 이고 $( \alpha $) 는 0.005, $( \beta $) 는 11.1 이 사용되었다.
- 녹색 선이 원래 $( \sin(2\pi{x}) $) 곡선이고 빨간 선이 모델을 통해 만들어진 근사식이다. 
- 연한 붉은 색의 밴드가 평균 값 주변의 분산( $( \pm{1} $) )을 나타내고 있다.

### 출처(참고문헌)
- Pattern Recognition and Machine Learning = Christopher M. Bishop
- http://norman3.github.io/prml/

### 연결문서
[[1. Introduction]]