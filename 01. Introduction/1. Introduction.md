#PRML_Introduction

#전처리 는 #특징추출 이라고 하기도 한다.
특징추출 대상의 위치와 orientation에 제한조건을 주면 intra-class 가변성을 줄일 수 있고, 특징추출에 중요한 과정이다.

#전처리 를 함으로써 계산 속도를 높일 수 있다. 가령 Haar 모양 특징을 통해 얼굴을 검출하는 [[viola and jones]] 이 그러하다. #차원감소 의 예시로 들기도 한다.

#분류 문제는 입력 벡터를 제한된 숫자의 분리된 카테고리 중 하나에 할당하는 종류의 지도 학습 문제이다.

기대되는 출력값이 연속된 값일 경우에 #회귀 #regression 이라고 한다. 반응 물질의 농도, 온도, 압력이 주어졌을 경우 화학 반응을 통해 결과물이 얼마나 산출될 것인지를 예측하는 것이 이러한 회귀 문제의 예시이다.

타겟 벡터 없이 훈련데이터가 벡터 x로만 주어질 경우 패턴인식문제를 #비지도학습 문제라고 하며,  데이터 내에서 비슷한 예시들의 집단을 찾는 #clustering 문제, 입력 공간에서의 데이터 분포를 찾는 #density_estimation 문제, 높은 차원의 데이터를 이차원 또는 삼차원에 투영하여 이해하기 쉽게 만들어 보여주는 #시각화 등이 비지도 학습의 예시이다.

#강화학습 은 주어진 상황에서 보상을 최대화하기 위한 행동을 찾는 문제를 푸는 방법이다. 강화 학습은 지도 학습의 경우와 달리 학습 알고리즘에 입력값과 최적의 출력값을 예시로 주지 않는다. 

## 일반화(Generalization)의 문제

- 우리가 관찰한 데이터는 **출현 가능한** 데이터의 **일부**일 뿐이다.
- 우리에게 주어진 일부 데이터로부터 전체 데이터를 아우르는 패턴을 발견해야 한다.
   - 따라서 이러한 패턴은 아직 발현되지 않은 데이터에 대해서도 잘 설명할 수 있어야 한다.
- 문제 범위를 축소하기 위해 입력 데이터를 사전에 정제하는 작업을 진행하기도 한다.
   - 이러한 작업을 *pre-process* 또는 *feature extraction* 이라고 한다.


## 기계 학습의 종류

- **Supervised Learning** 
   - 분류(Classification), 회귀(Regression)
- **Unsupervised Learning**
   - 클러스터링(Clustering), 비쥬얼라이제이션(Visualization)
- **Reinforcement Learning**
   - 주어진 상황에서 보상(reward)을 최대로 만드는 액션을 찾는 문제
   - Supervised Learning 과 다르게 타겟 값이 주어지지 않는다.
   - Exploration과 Exploitation 의 trade-off 문제
   - 이 교재에서는 다루지 않는다.

### 출처(참고문헌)
- Pattern Recognition and Machine Learning = Christopher M. Bishop
- http://norman3.github.io/prml/

### 연결문서
[[1. Introduction]]